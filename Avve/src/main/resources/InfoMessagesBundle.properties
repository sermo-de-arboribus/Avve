explainControlledVocabularyOption=A path to a controlledvocabulary file, with one lemmatized term per line. The output file will then contain one attribute for each controlled term, giving term frequencies.
explainInputFolderOption=A directory path; the directory should have subdirectories named after the class that the contained files belong to.
explainInputOption=The Epub file that serves as an input for learning of classifying.
explainLemmaCorrectionOption=Specifies, if a manual lemma correction, using the lemmatizer-de-dict.txt resource file, shall be applied.
explainMultiLabelOption=If this argument is passed, training instances can belong to more than one class. Input files should be in folders where folder names are comma-separated listings of the classes.
explainPosCorrectionOption=Specifies, if a manual part-of-speech tag correction, using the postag-de-dict.txt resource file, shall be applied.
explainWarengruppeOption=A Warengruppe value according to the specification of the German book trade association. If provided, this will be used as a target value for training.
explainWordVectorSizeOption=A number to indicate how many terms per document will be output in the string parameter for Weka word vector building.
numberOfSpineItemsFound=%d spine entries found.
startReadingOebpsSpine=Scanning the spine of the OEBPS file:
workingOnContentItem=Working on content document %s now.

avve.epubhandling.auxiliarVerbMessage=The auxiliar verb %s at position %d of sentence %d has POS tag %s and could indicate a passive sentence.
avve.epubhandling.languageDetermination=Trying to determine the language from `%s´.
avve.epubhandling.participleMessage=The participle %s at position %d of sentence %d has POS tag %s and could indicate a passive sentence.
avve.epubhandling.uniqueIdentifierFound=Found unique document identifier %s from EPUB's OPF metadata.

avve.extractor.couldNotFindDocumentInLuceneIndex=Could not find document with identifier `%s´ in the Lucene index.
avve.extractor.couldNotFindLuceneTermInEbookContentData=Could not find the Lucene index term `%s´ in the document lemmas list. 
avve.extractor.executionTime=Execution took %s seconds.
avve.extractor.numberOfFilesToProcess=Number of files to process: %d.
avve.extractor.programFinished=Program finished at %s.
avve.extractor.retrievingTfIdfForDocument=Retrieving TF/IDF values for document with ID `%s´.
avve.extractor.secondIterationStarted=Started second iteration: Building XRFF files with statistics.
avve.extractor.started=Program started at %s.
avve.extractor.startEpubExtraction=Starting to extract EPUB file
avve.extractor.startWorkingOnSerializedTempFiles=Starting to work on temporary serialized object from step 1

avve.services.combiningXrffFiles=Starting to combine individual XRFF files via XSLT script...
avve.services.generatingMultiClassArffFile=Generating a multi-class ARFF file for MEKA...
avve.services.lucene.customGermanAnalyzerBuild=A German language Lucene analyzer has been built.
avve.services.lucene.standardAnalyzerBuild=A standard Lucene analyzer has been built.

avve.textpreprocess.lemmatizerStarted=The lemmatizer started working on %s.
avve.textpreprocess.numberOfLemmasDetected=%d unique lemmas detected.
avve.textpreprocess.numberOfSentencesDetected=%d sentences detected.
avve.textpreprocess.numberOfTokensDetected=%d tokens detected.
avve.textpreprocess.sentenceDetectorStarted=Starting to detect sentences.
avve.textpreprocess.partOfSpeechTaggerDifferentPos=The Part Of Speech tagger has found %d different parts of speech.
avve.textpreprocess.removingPunctuation=Removing punctuation from tokens...
avve.textpreprocess.tokenizingText=Tokenizing...
avve.textpreprocess.toLowerCaseEnded=Transformed text to lower case done.
avve.textpreprocess.toLowerCaseStarted=Transforming text to lower case...
avve.textpreprocess.wordFrequencyCounted=WordFrequencyPreprocessor has counted %d unique words.
avve.textpreprocess.wordFrequencyProcessorStart=Starting to count word frequencies with WordFrequencyPreprocessor