explainControlledVocabularyOption=A path to a controlledvocabulary file, with one lemmatized term per line. The output file will then contain one attribute for each controlled term, giving term frequencies.
explainDoNotIndexForeignWordsOption=If this flag is set, then lemmas/tokens that have been tagged as foreign words ("FM") will not be pushed to the Lucene index.
explainInputFolderOption=A directory path; the directory should have subdirectories named after the class that the contained files belong to.
explainInputOption=The Epub file that serves as an input for learning of classifying.
explainLemmaCorrectionOption=Specifies, if a manual lemma correction, using the lemmatizer-de-dict.txt resource file, shall be applied.
explainMultiLabelOption=If this argument is passed, training instances can belong to more than one class. Input files should be in folders where folder names are comma-separated listings of the classes.
explainNoLigaturesOption=If this option is set, common purely typographic ligatures (like e.g. ff, fi) will be normalized to their two- or three-letter counterparts. Orthographic ligatures (e.g. oe, ß) are not touched.
explainUrlNormOption=If this argument flag is set, all http(s) and ftp urls will be normalized to http(s)|ftp://, thereby eliminating random character sequences from urls from the word index.
explainPosCorrectionOption=Specifies, if a manual part-of-speech tag correction, using the postag-de-dict.txt resource file, shall be applied.
explainThesaurusOption=If this flag is set, a thesaurus is used to add hyperonyms to the extracted text. An Open Thesaurus DB must be available and configured (resources/openthesaurus/openthesaurus.properties)
explainWarengruppeOption=A Warengruppe value according to the specification of the German book trade association. If provided, this will be used as a target value for training.
explainWordVectorSizeOption=A number to indicate how many terms per document will be output in the string parameter for Weka word vector building.
numberOfSpineItemsFound=%d spine entries found.
startReadingOebpsSpine=Scanning the spine of the OEBPS file:
workingOnContentItem=Working on content document %s now.

avve.epubhandling.auxiliarVerbMessage=The auxiliar verb %s at position %d of sentence %d has POS tag %s and could indicate a passive sentence.
avve.epubhandling.languageDetermination=Trying to determine the language from `%s´.
avve.epubhandling.participleMessage=The participle %s at position %d of sentence %d has POS tag %s and could indicate a passive sentence.
avve.epubhandling.uniqueIdentifierFound=Found unique document identifier %s from EPUB's OPF metadata.

avve.extractor.couldNotFindDocumentInLuceneIndex=Could not find document with identifier `%s´ in the Lucene index.
avve.extractor.couldNotFindLuceneTermInEbookContentData=Could not find the Lucene index term `%s´ in the document lemmas list. 
avve.extractor.executionTime=Execution took %s seconds.
avve.extractor.numberOfFilesToProcess=Number of files to process: %d.
avve.extractor.programFinished=Program finished at %s.
avve.extractor.retrievingTfIdfForDocument=Retrieving TF/IDF values for document with ID `%s´.
avve.extractor.secondIterationStarted=Started second iteration: Building XRFF files with statistics.
avve.extractor.started=Program started at %s.
avve.extractor.startEpubExtraction=Starting to extract EPUB file
avve.extractor.startWorkingOnSerializedTempFiles=Starting to work on temporary serialized object from step 1

avve.meka.buildingClassifier=Building classifier...
avve.meka.classLabels=Retained class labels: %s.
avve.meka.loadingTestingData=Testing data is being loaded from %s.
avve.meka.loadingTrainingData=Training data is being loaded from %s.
avve.meka.testClassFrequencies=Class frequencies in test set: %s.
avve.meka.trainingClassFrequencies=Class frequencies in training set: %s.

avve.services.combiningXrffFiles=Starting to combine individual XRFF files via XSLT script...
avve.services.configuringDataPrepreprocessorService=Configuring data preprocessor service...
avve.services.generatingMultiClassArffFile=Generating a multi-class ARFF file for MEKA...
avve.services.lucene.customGermanAnalyzerBuild=A German language Lucene analyzer has been built.
avve.services.lucene.standardAnalyzerBuild=A standard Lucene analyzer has been built.
avve.services.textpreProcessorAdded=`%s´ has been added.

avve.textpreprocess.dbLookupsPerformed=Number of database lookups performed: %d.
avve.textpreprocess.hyperonymPreprocessorCreated=A HyperonymPreprocessor has been instantiated.
avve.textpreprocess.lemmatizerStarted=The lemmatizer started working on %s.
avve.textpreprocess.numberOfLemmasDetected=%d unique lemmas detected.
avve.textpreprocess.numberOfSentencesDetected=%d sentences detected.
avve.textpreprocess.numberOfTokensDetected=%d tokens detected.
avve.textpreprocess.sentenceDetectorStarted=Starting to detect sentences.
avve.textpreprocess.partOfSpeechTaggerDifferentPos=The PartOfSpeech tagger has found %d different parts of speech.
avve.textpreprocess.partOfSpeechTaggingStarted=Starting to tag parts of speech
avve.textpreprocess.removingPunctuation=Removing punctuation from tokens...
avve.textpreprocess.replacingLigatures=Replacing ligatures...
avve.textpreprocess.tokenizingText=Tokenizing...
avve.textpreprocess.toLowerCaseEnded=Transformed text to lower case done.
avve.textpreprocess.toLowerCaseStarted=Transforming text to lower case...
avve.textpreprocess.urlNormalizerCreated=A UrlNormalizer text preprocessor object has been instantiated.
avve.textpreprocess.urlsNormalized=%d URLs have been normalized.
avve.textpreprocess.wordFrequencyCounted=WordFrequencyPreprocessor has counted %d unique words.
avve.textpreprocess.wordFrequencyProcessorStart=Starting to count word frequencies with WordFrequencyPreprocessor