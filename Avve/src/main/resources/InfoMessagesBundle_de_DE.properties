explainControlledVocabularyOption=Ein Pfad zu einer Controlled-Vocabulary-Datei, die einen lemmatisierten Term pro Zeile enthält. Die Ausgabedatei enth\u00e4lt dann für jeden Term ein Attribut mit der Termanzahl.
explainDoNotIndexForeignWordsOption=Wenn dieses Kennzeichen gesetzt ist, werden Lemmata/Tokens, welche als fremdsprachiges Material ("FM") getaggt wurden, nicht in den Lucene-Index geschoben.
explainInputFolderOption=Ein Pfad zu einem Verzeichnis, in dem sich Dateien in Unterverzeichnissen befinden, deren Namen wiederum der Dateiklasse entspricht.
explainInputOption=Der Pfad zur EPUB-Eingabedatei
explainLemmaCorrectionOption=Gibt an, ob eine manuelle Lemmakorrektur unter Verwendung der Ressourcendatei lemmatizer-de-dict.txt angewendet werden soll.
explainMultiLabelOption=Dieser Parameter gibt an, dass eine Trainingsinstanz zu mehr als einer Klasse gehören kann. Die Ausgabe der Vorverarbeitung erfolgt in einem Format, das nicht von WEKA, sondern von MEKA verarbeitet werden kann.
explainPosCorrectionOption=Gibt an, ob eine manuelle Wortartenkorrektur unter Verwendung der Ressourcendatei postag-de-dict.txt angewendet werden soll.
explainWarengruppeOption=Eine Warengruppe nach der Warengruppensystematik des Deutschen Buchhandels. Wird ein Wert angegeben, wird er zum Trainieren eines Dokumentenmodells verwendet.
explainWordVectorSizeOption=Eine Zahl, die angibt, wie viele Wörter in dem Attribut ausgegeben werden, welches zum Aufbau eines Weka-Wortvektors verwendet werden kann.
startReadingOebpsSpine=Lese Spine-Element der OEBPS-Datei ein:
numberOfSpineItemsFound=%d Spine-Eintr\u00e4ge gefunden.
workingOnContentItem=Verarbeite jetzt die Inhaltsdatei %s

avve.epubhandling.auxiliarVerbMessage=Das Hilfsverb %s an Position %d in Satz %d hat POS-Tag %s und k\u00F6nnte auf einen Passivsatz hindeuten.
avve.epubhandling.languageDetermination=Versuche, die Textsprache zu erkennen aus `%s´.
avve.epubhandling.participleMessage=Das Partizip %s an Position %d in Satz %d hat POS-Tag %s und k\u00F6nnte auf einen Passivsatz hindeuten.
avve.epubhandling.uniqueIdentifierFound=Eindeutige ID `%s´ in den EPUB-Metadaten gefunden.
avve.epubhandling.tocDepthNumberFormatError=Die Tiefe des Inhaltsverzeichnisses konnte nicht ermittelt werden. Tiefe wird auf Wert 0 gesetzt.

avve.extractor.couldNotFindDocumentInLuceneIndex=Das Dokument mit der ID `%s´ konnte im Lucene-Index nicht gefunden werden.
avve.extractor.couldNotFindLuceneTermInEbookContentData=Der Lucene-Index-Term `%s´ konnte nicht in der Lemmataliste der E-Book-Datei gefunden werden. 
avve.extractor.executionTime=Die Ausf\u00fchrung dauerte %s Sekunden.
avve.extractor.numberOfFilesToProcess=Anzahl der zu verarbeitenden Dateien: %d.
avve.extractor.programFinished=Programm beendet zum Zeitpunkt %s.
avve.extractor.retrievingTfIdfForDocument=Beginne mit dem Lesen der TF/IDF-Werte f\u00fcr das Dokument mit der ID `%s´.
avve.extractor.secondIterationStarted=Zweite Iteration beginnt: XRFF-Dateien mit Textstatistiken werden erzeugt.
avve.extractor.started=Program gestartet zum Zeitpunkt %s.
avve.extractor.startEpubExtraction=Beginne mit der Verarbeitung der folgenden EPUB-Datei
avve.extractor.startWorkingOnSerializedTempFiles=Beginne mit der Verarbeitung der serialisierten tempor\u00e4ren Datei aus Schritt 1

avve.services.combiningXrffFiles=F\u00fge die erzeugten einzelnen XRFF-Dateien zu einer kombinierten XRFF-Datei zusammen...
avve.services.configuringDataPrepreprocessorService=Der Datenpr\u00E4prozessor-Dienst wird initialisiert...
avve.services.generatingMultiClassArffFile=Erzeuge eine Multiklassen-ARFF-Datei im MEKA-Format aus den zuvor erzeugten einzelnen XRFF-Dateien...
avve.services.lucene.customGermanAnalyzerBuild=Ein deutscher Lucene-Analyzer wurde erstellt.
avve.services.lucene.standardAnalyzerBuild=Ein Standard-Analyzer f\u00fcr Lucene wurde erstellt.
avve.services.textpreProcessorAdded=`%s´ wurde hinzugef\u00fcgt.

avve.textpreprocess.lemmatizerStarted=Der Lemmatizer startet nun f\u00fcr %s.
avve.textpreprocess.numberOfLemmasDetected=%d eindeutige Lemmata gefunden.
avve.textpreprocess.numberOfSentencesDetected=%d S\u00E4tze entdeckt.
avve.textpreprocess.numberOfTokensDetected=%d Tokens entdeckt.
avve.textpreprocess.partOfSpeechTaggerDifferentPos=Der Wortarten-Auszeichner hat %d verschiedene Wortarten gefunden.
avve.textpreprocess.partOfSpeechTaggingStarted=Beginne mit der Auszeichnung der Wortarten.
avve.textpreprocess.removingPunctuation=Entferne Interpunktion aus den Tokens...
avve.textpreprocess.sentenceDetectorStarted=Beginne mit der Satzerkennung. 
avve.textpreprocess.tokenizingText=Zerlege Text in Tokens...
avve.textpreprocess.toLowerCaseEnded=Text wurde in Kleinbuchstaben transformiert.
avve.textpreprocess.toLowerCaseStarted=Beginne damit, den Text in Kleinbuchstaben umzuwandeln.
avve.textpreprocess.wordFrequencyCounted=WordFrequencyPreprocessor hat %d verschiedene W\u00F6rter gez\u00E4hlt.
avve.textpreprocess.wordFrequencyProcessorStart=WordFrequencyPreprocessor z\u00E4hlt jetzt die Worth\u00E4ufigkeiten.